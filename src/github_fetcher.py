"""
GitHub Fetcher - ä» GitHub API è·å–ä»“åº“æ•°æ®
ä½¿ç”¨ GitHub Search API æŒ‰è¯é¢˜è·å–ä»“åº“
"""
import time
import requests
from typing import Dict, List, Optional
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
import re

from src.config import (
    GITHUB_TOKEN, TOPIC, GITHUB_API_BASE,
    GITHUB_PER_PAGE, GITHUB_MAX_PAGES, GITHUB_SEARCH_SORT,
    GITHUB_SEARCH_ORDER, FETCH_REQUEST_DELAY,
    TRENDING_MODE, TRENDING_API_MODE, TRENDING_DAYS, TRENDING_MIN_STARS,
    TRENDING_LANGUAGE, TRENDING_SINCE
)


class GitHubFetcher:
    """ä» GitHub API è·å–ä»“åº“æ•°æ®"""

    def __init__(self, token: str = None, topic: str = None):
        """
        åˆå§‹åŒ–

        Args:
            token: GitHub Personal Access Token
            topic: è¦æœç´¢çš„ GitHub Topic
        """
        self.token = token or GITHUB_TOKEN
        self.topic = topic or TOPIC
        self.api_base = GITHUB_API_BASE
        self.per_page = GITHUB_PER_PAGE
        self.max_pages = GITHUB_MAX_PAGES
        self.delay = FETCH_REQUEST_DELAY

        self.session = requests.Session()
        self.session.headers.update({
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": "GitHub-Topics-Trending/1.0"
        })

        if self.token:
            self.session.headers.update({
                "Authorization": f"Bearer {self.token}"
            })

        self.rate_limit_remaining = 5000
        self.rate_limit_reset = None

    def fetch(self, sort_by: str = None, limit: int = None, mode: str = None) -> List[Dict]:
        """
        è·å–ä»“åº“åˆ—è¡¨

        Args:
            sort_by: æ’åºæ–¹å¼ (stars, forks, updated)
            limit: æœ€å¤§è¿”å›æ•°é‡
            mode: æ¨¡å¼ ("topic" æˆ– "trending")ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–

        Returns:
            [
                {
                    "rank": 1,
                    "repo_name": "owner/repo",
                    "owner": "owner",
                    "stars": 1000,
                    "forks": 100,
                    "issues": 10,
                    "language": "Python",
                    "url": "https://github.com/owner/repo",
                    "description": "...",
                    "topics": ["topic1", "topic2"],
                    "created_at": "2024-01-01T00:00:00Z",
                    "updated_at": "2024-01-01T00:00:00Z"
                },
                ...
            ]
        """
        mode = mode or TRENDING_MODE
        sort_by = sort_by or GITHUB_SEARCH_SORT
        limit = limit or (self.per_page * self.max_pages)

        if mode == "trending":
            return self._fetch_trending(sort_by, limit)
        else:
            return self._fetch_topic(sort_by, limit)

    def _fetch_topic(self, sort_by: str, limit: int) -> List[Dict]:
        """
        è·å–æŒ‡å®šè¯é¢˜ä¸‹çš„ä»“åº“åˆ—è¡¨

        Args:
            sort_by: æ’åºæ–¹å¼
            limit: æœ€å¤§è¿”å›æ•°é‡

        Returns:
            ä»“åº“åˆ—è¡¨
        """
        print(f"ğŸ“¡ æ­£åœ¨è·å–è¯é¢˜ '{self.topic}' çš„ä»“åº“åˆ—è¡¨...")
        print(f"   æ’åºæ–¹å¼: {sort_by}")

        repos = []
        page = 1

        while page <= self.max_pages and len(repos) < limit:
            # æ£€æŸ¥é€Ÿç‡é™åˆ¶
            if self.rate_limit_remaining < 10:
                self._wait_for_rate_limit()

            data = self._fetch_page(page, sort_by, mode="topic")

            if not data or "items" not in data:
                break

            items = data["items"]
            if not items:
                break

            for item in items:
                repo = self._parse_repo_item(item, len(repos) + 1)
                repos.append(repo)

                if len(repos) >= limit:
                    break

            # æ›´æ–°é€Ÿç‡é™åˆ¶ä¿¡æ¯
            self._update_rate_limit(data)

            print(f"   ç¬¬ {page} é¡µ: è·å– {len(items)} ä¸ªä»“åº“ (ç´¯è®¡ {len(repos)})")

            # å¦‚æœè¿”å›æ•°é‡å°‘äº per_pageï¼Œè¯´æ˜å·²ç»åˆ°æœ€åä¸€é¡µ
            if len(items) < self.per_page:
                break

            page += 1

            # è¯·æ±‚é—´éš”
            if page <= self.max_pages and len(repos) < limit:
                time.sleep(self.delay)

        print(f"âœ… æˆåŠŸè·å– {len(repos)} ä¸ªä»“åº“")
        return repos

    def _fetch_trending(self, sort_by: str, limit: int) -> List[Dict]:
        """
        è·å– GitHub Trending é£æ ¼çš„ä»“åº“ï¼ˆè¿‘æœŸé«˜å¢é•¿é¡¹ç›®ï¼‰

        Args:
            sort_by: æ’åºæ–¹å¼
            limit: æœ€å¤§è¿”å›æ•°é‡

        Returns:
            ä»“åº“åˆ—è¡¨
        """
        # ä½¿ç”¨ç¬¬ä¸‰æ–¹å®˜æ–¹ Trending API
        if TRENDING_API_MODE == "official":
            return self._fetch_trending_from_page(TRENDING_SINCE, limit)
        else:
            # ä½¿ç”¨ Search API æ¨¡æ‹Ÿ
            return self._fetch_trending_from_search(sort_by, limit)

    def fetch_all_trending_periods(self, limit: int = 25) -> Dict[str, List[Dict]]:
        """
        ä¸€æ¬¡æ€§è·å– dailyã€weeklyã€monthly ä¸‰ä¸ªæ—¶é—´èŒƒå›´çš„ Trending æ•°æ®

        Args:
            limit: æ¯ä¸ªæ—¶é—´èŒƒå›´è·å–çš„æœ€å¤§æ•°é‡

        Returns:
            {
                "daily": [...],
                "weekly": [...],
                "monthly": [...]
            }
        """
        print("=" * 70)
        print("ğŸ”¥ å¼€å§‹è·å–å¤šæ—¶é—´æ®µ Trending æ•°æ®")
        print("=" * 70)
        print()

        results = {}

        for period in ["daily", "weekly", "monthly"]:
            print(f"\nğŸ“… æ­£åœ¨è·å– {period.upper()} Trending...")
            print("-" * 70)

            # ä¸´æ—¶ä¿®æ”¹é…ç½®
            original_since = TRENDING_SINCE

            try:
                # ç›´æ¥ä¼ é€’ period å‚æ•°
                repos = self._fetch_trending_with_period(period, limit)
                results[period] = repos

                print(f"âœ… {period.upper()}: æˆåŠŸè·å– {len(repos)} ä¸ªé¡¹ç›®")

                # è¯·æ±‚é—´éš”ï¼Œé¿å…è¿‡å¿«
                if period != "monthly":
                    time.sleep(1)

            except Exception as e:
                print(f"âŒ {period.upper()}: è·å–å¤±è´¥ - {e}")
                results[period] = []

        print()
        print("=" * 70)
        print(f"ğŸ‰ å®Œæˆï¼å…±è·å–:")
        print(f"   ğŸ“Š Today:     {len(results.get('daily', []))} ä¸ªé¡¹ç›®")
        print(f"   ğŸ“Š This Week: {len(results.get('weekly', []))} ä¸ªé¡¹ç›®")
        print(f"   ğŸ“Š This Month:{len(results.get('monthly', []))} ä¸ªé¡¹ç›®")
        print("=" * 70)

        return results

    def _fetch_trending_with_period(self, period: str, limit: int) -> List[Dict]:
        """
        è·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„ Trending æ•°æ®

        Args:
            period: "daily", "weekly", or "monthly"
            limit: æœ€å¤§è¿”å›æ•°é‡

        Returns:
            ä»“åº“åˆ—è¡¨
        """
        if TRENDING_API_MODE == "official":
            return self._fetch_trending_from_page(period, limit)
        else:
            # Search API æ¨¡å¼ä¸‹ï¼Œæ—¶é—´èŒƒå›´æ˜ å°„
            days_map = {"daily": 1, "weekly": 7, "monthly": 30}
            days = days_map.get(period, 7)
            return self._fetch_trending_from_search("stars", limit, days)

    def _fetch_trending_from_page(self, period: str, limit: int) -> List[Dict]:
        """
        çˆ¬å– GitHub Trending é¡µé¢è·å–æ•°æ®ï¼ˆå’Œå®˜æ–¹é¡µé¢å®Œå…¨ä¸€è‡´ï¼‰

        Args:
            period: "daily", "weekly", or "monthly"
            limit: æœ€å¤§è¿”å›æ•°é‡

        Returns:
            ä»“åº“åˆ—è¡¨
        """
        # æ„å»º GitHub Trending URL
        trending_url = "https://github.com/trending"

        params = {}
        if TRENDING_LANGUAGE:
            trending_url = f"{trending_url}/{TRENDING_LANGUAGE.lower()}"

        # since å‚æ•°
        params["since"] = period

        print(f"ğŸ”¥ æ­£åœ¨çˆ¬å– GitHub Trending é¡µé¢...")
        print(f"   æ—¶é—´èŒƒå›´: {period}")
        if TRENDING_LANGUAGE:
            print(f"   è¯­è¨€è¿‡æ»¤: {TRENDING_LANGUAGE}")

        try:
            # çˆ¬å–é¡µé¢
            headers = {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
            }
            response = requests.get(trending_url, params=params, headers=headers, timeout=30)
            response.raise_for_status()

            # è§£æ HTML
            soup = BeautifulSoup(response.text, 'html.parser')
            articles = soup.find_all('article', class_='Box-row')

            if not articles:
                print(f"   âš ï¸ æœªæ‰¾åˆ° trending é¡¹ç›®")
                return []

            repos = []
            for i, article in enumerate(articles[:limit], 1):
                repo = self._parse_trending_html(article, i)
                if repo:
                    repos.append(repo)

            print(f"âœ… æˆåŠŸçˆ¬å– {len(repos)} ä¸ª Trending ä»“åº“")
            return repos

        except Exception as e:
            print(f"   âš ï¸ çˆ¬å– Trending é¡µé¢å¤±è´¥: {e}")
            print(f"   â„¹ï¸ é™çº§ä½¿ç”¨ Search API")
            return self._fetch_trending_from_search("stars", limit)

    def _parse_trending_html(self, article, rank: int) -> Optional[Dict]:
        """
        è§£æ GitHub Trending é¡µé¢çš„å•ä¸ªä»“åº“

        Args:
            article: BeautifulSoup article å…ƒç´ 
            rank: æ’å

        Returns:
            ä»“åº“ä¿¡æ¯å­—å…¸ï¼Œè§£æå¤±è´¥è¿”å› None
        """
        try:
            # è·å–ä»“åº“åç§°
            h2 = article.find('h2', class_='h3')
            if not h2:
                return None

            repo_link = h2.find('a')
            if not repo_link:
                return None

            repo_name = repo_link['href'].strip('/')
            owner, name = repo_name.split('/')

            # è·å–æè¿°
            description_elem = article.find('p', class_='col-9')
            description = description_elem.text.strip() if description_elem else ""

            # è·å–è¯­è¨€
            language_elem = article.find('span', attrs={'itemprop': 'programmingLanguage'})
            language = language_elem.text.strip() if language_elem else ""

            # è·å–æ˜Ÿæ ‡æ•°
            star_elem = article.find('span', class_='d-inline-block float-sm-right')
            stars_text = star_elem.text.strip() if star_elem else "0"
            stars = self._parse_number(stars_text)

            # è·å– fork æ•°
            fork_elem = article.find_all('a', class_='Link--muted')
            forks = 0
            for elem in fork_elem:
                if 'network/members' in elem.get('href', ''):
                    forks = self._parse_number(elem.text.strip())
                    break

            # è·å–ä»Šæ—¥æ˜Ÿæ ‡å¢é•¿
            stars_today_elem = article.find('span', class_='d-inline-block float-sm-right')
            trending_stars = 0
            if stars_today_elem:
                today_text = stars_today_elem.find_next_sibling('span')
                if today_text:
                    trending_stars = self._parse_number(today_text.text.strip())

            return {
                "rank": rank,
                "repo_name": repo_name,
                "owner": owner,
                "name": name,
                "stars": stars,
                "forks": forks,
                "issues": 0,
                "language": language,
                "url": f"https://github.com/{repo_name}",
                "description": description,
                "topics": [],
                "created_at": "",
                "updated_at": "",
                "trending_stars": trending_stars,
            }

        except Exception as e:
            print(f"   âš ï¸ è§£æä»“åº“å¤±è´¥: {e}")
            return None

    def _parse_number(self, text: str) -> int:
        """è§£ææ•°å­—ï¼ˆæ”¯æŒ 1k, 1.5k ç­‰æ ¼å¼ï¼‰"""
        text = text.replace(',', '').strip()
        match = re.search(r'([\d.]+)\s*([km])?', text.lower())
        if not match:
            return 0

        num = float(match.group(1))
        unit = match.group(2)

        if unit == 'k':
            return int(num * 1000)
        elif unit == 'm':
            return int(num * 1000000)
        return int(num)

    def _parse_trending_api_item(self, item: Dict, rank: int) -> Dict:
        """
        è§£æç¬¬ä¸‰æ–¹ Trending API è¿”å›çš„æ•°æ®

        Args:
            item: API è¿”å›çš„ä»“åº“é¡¹
            rank: æ’å

        Returns:
            æ ‡å‡†åŒ–çš„ä»“åº“ä¿¡æ¯
        """
        # ç¬¬ä¸‰æ–¹ API è¿”å›æ ¼å¼ï¼š
        # {
        #   "author": "owner",
        #   "name": "repo",
        #   "url": "https://github.com/owner/repo",
        #   "description": "...",
        #   "language": "Python",
        #   "stars": 1000,
        #   "forks": 100,
        #   "currentPeriodStars": 50,  # æœ¬æœŸå¢é•¿
        #   ...
        # }

        owner = item.get("author", "")
        name = item.get("name", "")
        repo_name = f"{owner}/{name}"

        return {
            "rank": rank,
            "repo_name": repo_name,
            "owner": owner,
            "name": name,
            "stars": item.get("stars", 0),
            "forks": item.get("forks", 0),
            "issues": 0,  # API ä¸æä¾›
            "language": item.get("language", ""),
            "url": item.get("url", f"https://github.com/{repo_name}"),
            "description": item.get("description", ""),
            "topics": [],  # API ä¸æä¾›
            "created_at": "",  # API ä¸æä¾›
            "updated_at": "",  # API ä¸æä¾›
            "trending_stars": item.get("currentPeriodStars", 0),  # é¢å¤–ä¿¡æ¯ï¼šæœ¬æœŸå¢é•¿
        }

    def _fetch_trending_from_search(self, sort_by: str, limit: int, days: int = None) -> List[Dict]:
        """
        è·å– GitHub Trending é£æ ¼çš„ä»“åº“ï¼ˆè¿‘æœŸé«˜å¢é•¿é¡¹ç›®ï¼‰

        Args:
            sort_by: æ’åºæ–¹å¼
            limit: æœ€å¤§è¿”å›æ•°é‡
            days: æœ€è¿‘ N å¤©ï¼ˆå¦‚æœä¸æŒ‡å®šï¼Œä½¿ç”¨ TRENDING_DAYSï¼‰

        Returns:
            ä»“åº“åˆ—è¡¨
        """
        cutoff_date = (datetime.now() - timedelta(days=days or TRENDING_DAYS)).strftime("%Y-%m-%d")

        print(f"ğŸ”¥ æ­£åœ¨è·å– GitHub Trending ä»“åº“...")
        print(f"   æ—¶é—´èŒƒå›´: æœ€è¿‘ {TRENDING_DAYS} å¤©æ´»è·ƒ (pushed>{cutoff_date})")
        print(f"   æœ€ä½æ˜Ÿæ ‡: {TRENDING_MIN_STARS}+")
        if TRENDING_LANGUAGE:
            print(f"   è¯­è¨€è¿‡æ»¤: {TRENDING_LANGUAGE}")
        print(f"   æ’åºæ–¹å¼: {sort_by}")

        repos = []
        page = 1

        while page <= self.max_pages and len(repos) < limit:
            # æ£€æŸ¥é€Ÿç‡é™åˆ¶
            if self.rate_limit_remaining < 10:
                self._wait_for_rate_limit()

            data = self._fetch_page(page, sort_by, mode="trending")

            if not data or "items" not in data:
                break

            items = data["items"]
            if not items:
                break

            for item in items:
                repo = self._parse_repo_item(item, len(repos) + 1)
                repos.append(repo)

                if len(repos) >= limit:
                    break

            # æ›´æ–°é€Ÿç‡é™åˆ¶ä¿¡æ¯
            self._update_rate_limit(data)

            print(f"   ç¬¬ {page} é¡µ: è·å– {len(items)} ä¸ªä»“åº“ (ç´¯è®¡ {len(repos)})")

            # å¦‚æœè¿”å›æ•°é‡å°‘äº per_pageï¼Œè¯´æ˜å·²ç»åˆ°æœ€åä¸€é¡µ
            if len(items) < self.per_page:
                break

            page += 1

            # è¯·æ±‚é—´éš”
            if page <= self.max_pages and len(repos) < limit:
                time.sleep(self.delay)

        print(f"âœ… æˆåŠŸè·å– {len(repos)} ä¸ª Trending ä»“åº“")
        return repos

    def _fetch_page(self, page: int, sort_by: str, mode: str = "topic") -> Optional[Dict]:
        """
        è·å–å•é¡µæ•°æ®

        Args:
            page: é¡µç 
            sort_by: æ’åºæ–¹å¼
            mode: "topic" æˆ– "trending"

        Returns:
            API å“åº”æ•°æ®
        """
        url = f"{self.api_base}/search/repositories"

        # æ ¹æ®æ¨¡å¼æ„å»ºæŸ¥è¯¢
        if mode == "trending":
            # Trending æ¨¡å¼ï¼šæœ€è¿‘Nå¤©æœ‰æ¨é€ï¼ˆæ´»è·ƒï¼‰ + æœ€ä½æ˜Ÿæ ‡æ•° + å¯é€‰è¯­è¨€è¿‡æ»¤
            cutoff_date = (datetime.now() - timedelta(days=TRENDING_DAYS)).strftime("%Y-%m-%d")
            query_parts = [
                f"pushed:>{cutoff_date}",  # æ”¹ç”¨ pushed: æ•è·æ´»è·ƒé¡¹ç›®
                f"stars:>={TRENDING_MIN_STARS}"
            ]
            if TRENDING_LANGUAGE:
                query_parts.append(f"language:{TRENDING_LANGUAGE}")
            query = " ".join(query_parts)
        else:
            # Topic æ¨¡å¼ï¼šæŒ‰è¯é¢˜æœç´¢
            query = f"topic:{self.topic}"

        params = {
            "q": query,
            "sort": sort_by,
            "order": GITHUB_SEARCH_ORDER,
            "per_page": self.per_page,
            "page": page
        }

        try:
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            return response.json()

        except requests.RequestException as e:
            print(f"   âš ï¸ è¯·æ±‚å¤±è´¥ (é¡µ {page}): {e}")
            return None

    def _parse_repo_item(self, item: Dict, rank: int) -> Dict:
        """
        è§£æä»“åº“æ•°æ®

        Args:
            item: GitHub API è¿”å›çš„ä»“åº“é¡¹
            rank: æ’å

        Returns:
            ä»“åº“ä¿¡æ¯å­—å…¸
        """
        owner_data = item.get("owner") or {}
        owner = owner_data.get("login", "")
        name = item.get("name", "")
        repo_name = f"{owner}/{name}"

        return {
            "rank": rank,
            "repo_name": repo_name,
            "owner": owner,
            "name": name,
            "stars": item.get("stargazers_count", 0),
            "forks": item.get("forks_count", 0),
            "issues": item.get("open_issues_count", 0),
            "language": item.get("language", ""),
            "url": item.get("html_url", ""),
            "description": item.get("description", ""),
            "topics": item.get("topics", []),
            "created_at": item.get("created_at", ""),
            "updated_at": item.get("updated_at", ""),
            "pushed_at": item.get("pushed_at", ""),
            "homepage": item.get("homepage", ""),
            "archived": item.get("archived", False),
        }

    def _update_rate_limit(self, response_data: Dict):
        """
        æ›´æ–°é€Ÿç‡é™åˆ¶ä¿¡æ¯

        Args:
            response_data: API å“åº”æ•°æ®
        """
        # æ³¨æ„ï¼šè¿™äº›ä¿¡æ¯åœ¨å®é™…è¯·æ±‚ä¸­ä»å“åº”å¤´è·å–
        # è¿™é‡Œåªæ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬
        pass

    def _wait_for_rate_limit(self):
        """ç­‰å¾…é€Ÿç‡é™åˆ¶é‡ç½®"""
        if self.rate_limit_reset:
            now = int(time.time())
            wait_time = self.rate_limit_reset - now + 1

            if wait_time > 0:
                print(f"â³ é€Ÿç‡é™åˆ¶å·²ç”¨å°½ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)

    def fetch_new_repos(self, days: int = 7) -> List[Dict]:
        """
        è·å–æœ€è¿‘åˆ›å»ºçš„ä»“åº“

        Args:
            days: æœ€è¿‘å¤šå°‘å¤©

        Returns:
            ä»“åº“åˆ—è¡¨
        """
        cutoff_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
        query = f"topic:{self.topic} created:>{cutoff_date}"

        print(f"ğŸ“¡ æ­£åœ¨è·å–æœ€è¿‘ {days} å¤©åˆ›å»ºçš„ä»“åº“...")

        repos = []
        page = 1

        while page <= self.max_pages:
            url = f"{self.api_base}/search/repositories"
            params = {
                "q": query,
                "sort": "stars",
                "order": "desc",
                "per_page": self.per_page,
                "page": page
            }

            try:
                response = self.session.get(url, params=params, timeout=30)
                response.raise_for_status()
                data = response.json()

                if not data or "items" not in data:
                    break

                items = data["items"]
                if not items:
                    break

                for item in items:
                    repo = self._parse_repo_item(item, len(repos) + 1)
                    repos.append(repo)

                print(f"   ç¬¬ {page} é¡µ: è·å– {len(items)} ä¸ªä»“åº“")

                if len(items) < self.per_page:
                    break

                page += 1
                time.sleep(self.delay)

            except requests.RequestException as e:
                print(f"   âš ï¸ è¯·æ±‚å¤±è´¥: {e}")
                break

        print(f"âœ… è·å–åˆ° {len(repos)} ä¸ªæ–°ä»“åº“")
        return repos

    def fetch_repo_details(self, owner: str, repo: str) -> Optional[Dict]:
        """
        è·å–å•ä¸ªä»“åº“çš„è¯¦ç»†ä¿¡æ¯

        Args:
            owner: ä»“åº“æ‹¥æœ‰è€…
            repo: ä»“åº“åç§°

        Returns:
            ä»“åº“è¯¦ç»†ä¿¡æ¯
        """
        url = f"{self.api_base}/repos/{owner}/{repo}"

        try:
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            return response.json()

        except requests.RequestException as e:
            print(f"   âš ï¸ è·å–ä»“åº“è¯¦æƒ…å¤±è´¥ {owner}/{repo}: {e}")
            return None


def fetch_repos(sort_by: str = "stars", limit: int = 100) -> List[Dict]:
    """ä¾¿æ·å‡½æ•°ï¼šè·å–ä»“åº“åˆ—è¡¨"""
    fetcher = GitHubFetcher()
    return fetcher.fetch(sort_by=sort_by, limit=limit)
